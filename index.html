<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>El TEG roto</title>
    <link rel="stylesheet" href="styles.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>



<div class="math-container">
    <h1>El TEG está roto</h1>

    <p> 
        Me duele admitirlo, porque es mi juego de mesa favorito. Pero el TEG está roto. El TEG está roto y lo que es peor, el RISK, su versión yankee, no lo está. Al menos por cómo me gusta jugarlo a mi, que es con dominación mundial y sin objetivos.
        Si quieren seguir disfrutando del juego, recomendaría no seguir leyendo, porque lo que sigue es el cálculo analítico de la probabilidad de ganar un país dada una cantidad de ejércitos atacantes y ejércitos defensores. Para el final verán lo que tanto me desilusionó a mi.
    </p>

    <h1>Las reglas</h1>
    
    <h1>Los casos básicos</h1>
    <h2>1vs1</h2>
    <p>
        Para terminar sabiendo cuál es la probabilidad de ganar un país al atacar y defender con A y D ejércitos, es importante calcular primero la probabilidad de ganar una sola batalla. El caso más fácil es cuando se juega un dado contra uno (1vs1). La probabilidad de que un dado aleatorio sea mayor estricto (o lo que es lo mismo, menor igual) a otro dado aleatorio, se puede leer de la siguiente tabla.
    </p>
    <p>
        <span class="tex">
            \[
            \begin{array}{c|cccccc}
                \text{D/A} & 1 & 2 & 3 & 4 & 5 & 6 \\
                \hline
                1   & \text{\(\color{red}{=}\)} & > & > & > & > & > \\
                2   & \text{\(\color{red}{<}\)} & \text{\(\color{red}{=}\)} & > & > & > & > \\
                3   & \text{\(\color{red}{<}\)} & \text{\(\color{red}{<}\)} & \text{\(\color{red}{=}\)} & > & > & > \\
                4   & \text{\(\color{red}{<}\)} & \text{\(\color{red}{<}\)} & \text{\(\color{red}{<}\)} & \text{\(\color{red}{=}\)} & > & > \\
                5   & \text{\(\color{red}{<}\)} & \text{\(\color{red}{<}\)} & \text{\(\color{red}{<}\)} & \text{\(\color{red}{<}\)} & \text{\(\color{red}{=}\)} & > \\
                6   & \text{\(\color{red}{<}\)} & \text{\(\color{red}{<}\)} & \text{\(\color{red}{<}\)} & \text{\(\color{red}{<}\)} & \text{\(\color{red}{<}\)} & \text{\(\color{red}{=}\)} \\
            \end{array}
            \]
        </span>
    </p>
    
    <p>
        En la tabla están todos los casos posibles, con los dados atacantes en las columnas y los dados defensores en las filas. Con un '<' se simboliza el caso donde el dado atacante es menor al dado defensor y con un signo '=' se representa el caso donde hay un empate entre ambos dados. Si contamos de esta tabla los casos donde el dado atacante es menor o igual al dado defensor (es decir, gana el defensor), entonces obtenemos una especie de triángulo (marcado en rojo). Sumando de arriba hacia abajo, obtenemos simplemente <span class="tex">1+2+3+4+5+6</span>. La cantidad total de casos es el tamaño total de la tabla, que es <span class="tex">6x6 = 36</span>. Entonces, la probabilidad de perder en el caso 1vs1 es

    </p>
    <span class="tex">
        \[
            \pi_{110} = \frac{1+2+3+4+5+6}{6^2} = \frac{7}{12} = 58,33%,
        \]
    </span>
    <p>
        donde con \pi_{110} simbolizo la probabilidad de ganar cero ejércitos al atacar uno contra uno (así uso la misma notación de <span id="cite1">[1]</span>). La probabilidad de ganar en este caso es simplemente
    </p>
    <span class="tex">
        \[
            \pi_{111} = 1 - \pi_{110} =\frac{1+2+3+4+5}{6^2} = \frac{5}{12} = 41,67%.
        \]
    </span>

    <h2>2vs1</h2>
    <p>
        En el caso de dos dados contra uno, se podría (erróneamente) pensar que la probabilidad de que dos dados sean mayores a uno es la probabilidad de que el primer o dado atacante sea mayor al dado defensor o que el segundo dado atacante sea mayor. Para poder sumar las probabilidades así, habría que asumir que los eventos son independientes, cosa que por otro lado tiene perfecto sentido: ¿qué le importa al segundo dado si el primer dado perdió o no? Parece imposible que el resultado del primer dado pueda afectar el resultado del segundo. Sin embargo, es exactamente así: los eventos no son independientes. Esto es porque la información sobre el resultado del primer dado sí cambia la probabilidad de ganar con el segundo dado. Antes de tirar el primer dado, no se sabe nada sobre qué puede sacar el dado defensor (y la distribución de probabilidad es uniforme). Pero si el primer dado gana, la distribución de probabilidad cambia. Por ejemplo, es imposible que el defensor haya tirado un seis, porque ningún dado atacante le habría podido ganar. Entonces automáticamente el segundo dado tiene más chances de ganar y el resultado del primer dado cambia la distribución de probabilidades del segundo dado.
    </p>
    <p>
        Afortunadamente, este caso sigue siendo simple y se puede resolver de una manera muy similar al caso anterior. Se puede armar un cubo donde una arista sean los dados del defensor y las otras dos aristas de un mismo vértice sean los dos dados del atacante. Vagamente uno se puede imaginar que si antes la probabilidad de perder estaba dada por un triángulo, ahora la probabilidad viene dada por una pirámide de base cuadrada. Además, los casos totales son todas las entradas del cubo (o equivalentemente todos los escenarios posibles), que son <span class="tex">6 \cdot 6 \cdot 6</span>. Cerrando los ojos y teniendo un poco de fe se llega al resultado 
    </p>
    <span class="tex">
        \[
            \pi_{210} = \frac{1^2 + 2^2 + 3^2 + 4^2 + 5^2 + 6^2}{6^3} = \frac{91}{216} = 42,13%.
        \]
    </span>
        <p>
            Igual que antes, la probabilidad de ganar es
        </p>
    <span class="tex">
        \[
            \pi_{211} = 1 - \pi_{210} = \frac{125}{216} = 57,87%.
        \]
    </span>

    <h2>3vs1</h2>
    <p>
        Ahora sí cerrando bien fuerte los ojos y confiando en el dios de la pirámide tetradimensional y el teseracto, podemos generalizar a 
    </p>
    <span class="tex">
        \[
            \pi_{210} = \frac{1^3 + 2^3 + 3^3 + 4^3 + 5^3 + 6^3}{6^4} = \frac{49}{144} = 24,03%
        \]
    </span>
    <p>
        Y la probabilidad de ganar
    </p>
    <span class="tex">
        \[
            \pi_{211} = 1 - \pi_{210} = \frac{95}{144} = 65,97%.
        \]
    </span>
    
    <h2>1vs2 y 1vs3</h2>
    <p>
        Los últimos dos casos fáciles que quedan
    </p>
    
    <h2>Teg infinito</h2>
    <p>
        Si se nos ocurriera jugar al teg con dados de N caras, la fórmula del caso 1vs1 es fácilmente generalizable a 

        \[
            \pi_{110}^{N} = \frac{\sum_{n=1}^N n }{N^2}
        \]

        Esta suma es igual a 

        \begin{equation}
            \frac{N \cdot (N + 1)}{2 \cdot N^2} = \frac{1}{2} + \frac{1}{2N}
        \end{equation}

        Tomando el límite de N tendiendo a infinito, vemos que la probabilidad de perder tiende a 1/2. Para el caso 2vs1, la fórmula queda

        \begin{equation}
            \pi_{210}^N = \frac{\sum_{n=1}^N n^2 }{N^3} = \frac{N \cdot (N+1) \cdot (2N + 1)}{6N^3}
        \end{equation}

        que tiende a 1/3 cuando N tiende a infinito. Análogamente, para el caso 3vs1,

        \begin{equation}
            \pi_{310}^N = \frac{\sum_{n=1}^N n^3 }{N^4} = \frac{N^2 \cdot (N+1)^2}{4N^4}
        \end{equation}

        que tiende a 1/4 cuando N tiende a infinito. En general (no tengo la demostración), supongo que la probabilidad de Avs1 dados es 1/A cuando N tiende a infinito. En particular, cabe notar que las probabilidades <span class="tex">\pi_{i11}^\infty</span> son mayores a <span class="tex">\pi_{i11}</span>, con lo que al atacante siempre le convendría atacar con un dado de la mayor cantidad de caras posibles (como también se notó en <span id="cite1">[2]</span>).
    </p>
    

    


    <h2>References</h2>
    <ol>
    <li id="ref1">Osborne, J. A. (2003). Markov Chains for the RISK Board Game Revisited. <em>Mathematics Magazine</em>, <em>76(2)</em>(Issue), 129-135. https://doi.org/10.2307/3219306</li>
    <li id="ref2">Blatt, Sharon (2002) "RISKy Business: An In-Depth Look at the Game RISK," <em>Rose-Hulman Undergraduate Mathematics Journal</em>, Vol. 3: Iss. 2, Article 3. </li>
    </ol>
</div>

</body>
</html>
